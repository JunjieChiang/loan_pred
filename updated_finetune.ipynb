{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: BNB_CUDA_VERSION=121 environment variable detected; loading libbitsandbytes_cuda121.so.\n",
      "This can be used to load a bitsandbytes version that is different from the PyTorch CUDA version.\n",
      "If this was unintended set the BNB_CUDA_VERSION variable to an empty string: export BNB_CUDA_VERSION=\n",
      "If you use the manual override make sure the right libcudart.so is in your LD_LIBRARY_PATH\n",
      "For example by adding the following to your .bashrc: export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:<path_to_cuda_dir/lib64\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from unsloth import FastLanguageModel\n",
    "import wandb\n",
    "from datasets import load_dataset, Dataset, DatasetDict\n",
    "from trl import SFTTrainer\n",
    "from transformers import TrainingArguments, Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff0aed2a-22b1-4ecb-8a94-f21cd68fd562",
   "metadata": {},
   "outputs": [],
   "source": [
    "# è´·æ¬¾æ•°æ®ç‰¹å¾å˜é‡æƒé‡\n",
    "feature_importance = {\n",
    "    \"Loan amount\": 1.2,\n",
    "    \"DTI\": 1.5,\n",
    "    \"Employment Title\": 0.8,\n",
    "    \"Employment Length\": 1.0,\n",
    "    \"Home Ownership\": 1.1,\n",
    "    \"Annual Income\": 1.6,\n",
    "    \"Verification Status\": 1.0,\n",
    "    \"Grade\": 2.0,\n",
    "    \"Purpose\": 0.9,\n",
    "    \"Description\": 0.7,\n",
    "    \"Title\": 0.8,\n",
    "    \"Open Accounts\": 1.3\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9da3f905-e5e2-483d-a704-004b66a97771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å°†é‡è¦æ€§åˆ—è¡¨è½¬æ¢ä¸ºä¸€ä¸ªå¯¹åº”çš„tensor\n",
    "importance_tensor = torch.tensor([v for v in feature_importance.values()], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f393160-0e92-4a27-9e88-29239c4cc52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å®šä¹‰è‡ªå®šä¹‰åŠ æƒäº¤å‰ç†µæŸå¤±å‡½æ•°\n",
    "class WeightedCrossEntropyLoss(nn.Module):\n",
    "    def __init__(self, importance_tensor):\n",
    "        super(WeightedCrossEntropyLoss, self).__init__()\n",
    "        self.importance_tensor = importance_tensor\n",
    "\n",
    "    def forward(self, predictions, targets, features):\n",
    "        # ç¡®ä¿ features ç»´åº¦ä¸ importance_tensor åŒ¹é…\n",
    "        if features.shape[1] != len(self.importance_tensor):\n",
    "            raise ValueError(f\"Feature dimension {features.shape[1]} does not match importance tensor length {len(self.importance_tensor)}\")\n",
    "\n",
    "        # ç¡®ä¿ importance_tensor å’Œ features åœ¨åŒä¸€è®¾å¤‡ä¸Š\n",
    "        self.importance_tensor = self.importance_tensor.to(features.device)\n",
    "\n",
    "        # å¦‚æœ predictions æ˜¯ [batch_size, seq_len, num_classes]ï¼Œéœ€è¦å±•å¹³ä¸º [batch_size * seq_len, num_classes]\n",
    "        if predictions.dim() == 3:\n",
    "            batch_size, seq_len, num_classes = predictions.size()\n",
    "            predictions = predictions.view(-1, num_classes)  # å±•å¹³ä¸º [batch_size * seq_len, num_classes]\n",
    "\n",
    "        # å¦‚æœ targets æ˜¯ [batch_size, seq_len]ï¼Œéœ€è¦å±•å¹³ä¸º [batch_size * seq_len]\n",
    "        if targets.dim() == 1:\n",
    "            # å‡è®¾æ¯ä¸ªæ ·æœ¬åœ¨åºåˆ—ä¸­æœ‰ç›¸åŒçš„æ ‡ç­¾ï¼Œé‡å¤ targets ä»¥åŒ¹é…åºåˆ—é•¿åº¦\n",
    "            targets = targets.unsqueeze(1).expand(-1, seq_len).contiguous()\n",
    "        \n",
    "        # ç¡®ä¿ targets è¢«å±•å¹³ä¸º [batch_size * seq_len]\n",
    "        targets = targets.view(-1)\n",
    "\n",
    "        # ç¡®ä¿ predictions å’Œ targets çš„ batch_size ä¸€è‡´\n",
    "        if predictions.size(0) != targets.size(0):\n",
    "            raise ValueError(f\"Expected predictions and targets to have the same batch_size after flattening, but got {predictions.size(0)} and {targets.size(0)}\")\n",
    "\n",
    "        # è®¡ç®—æ ‡å‡†äº¤å‰ç†µæŸå¤±\n",
    "        cross_entropy_loss = nn.CrossEntropyLoss()(predictions, targets)\n",
    "\n",
    "        # å°†ç‰¹å¾å¼ é‡å±•å¹³å¹¶ä¹˜ä»¥æƒé‡\n",
    "        weighted_features = features.view(features.size(0), -1) * self.importance_tensor.unsqueeze(0)\n",
    "\n",
    "        # ä½¿ç”¨åŠ æƒç‰¹å¾å¯¹æ•´ä½“æŸå¤±è¿›è¡ŒåŠ æƒ\n",
    "        weighted_loss = cross_entropy_loss * torch.mean(weighted_features)\n",
    "\n",
    "        return weighted_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48183d76-1f18-48ad-a89b-12ff2074563d",
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data_path = \"example\"\n",
    "dataset = load_dataset(loan_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7066c9f2-f9fb-40cb-a709-b34e4c61e20a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data: Dataset({\n",
      "    features: ['text', 'label'],\n",
      "    num_rows: 167153\n",
      "})\n",
      "train_data[0]: {'text': 'Loan amount: 13000, DTI: 20.05, Employment Title: DARCARS Toyota, Employment Length: 10+ years, Home Ownership: RENT, Annual Income: 55000.0, Verification Status: Not Verified, Grade: B-B3, Purpose: debt_consolidation, Description:   Pay off all my credit cards<br/>, Title: Credit Card, Open Accounts: 16', 'label': 0}\n"
     ]
    }
   ],
   "source": [
    "train_data = dataset[\"train\"]\n",
    "print(\"train_data:\", train_data)\n",
    "print(\"train_data[0]:\", train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06a01e10-f6ef-471a-b2b2-5f789d2ec610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# balance data sample\n",
    "label_1_data = [data for data in train_data if data['label'] == 1]\n",
    "label_0_data = [data for data in train_data if data['label'] == 0]\n",
    "\n",
    "num_label_1 = len(label_1_data)\n",
    "balanced_label_0_data = random.sample(label_0_data, num_label_1)\n",
    "balanced_data = label_1_data + balanced_label_0_data\n",
    "\n",
    "# random data layout\n",
    "random.shuffle(balanced_data)\n",
    "\n",
    "dataset = Dataset.from_list(balanced_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3572ac04-6e97-4955-9abf-f0faefe53b54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset size: 167153\n",
      "Balanced dataset size: 1920\n",
      "Number of label 1 samples: 960\n",
      "Number of label 0 samples: 960\n"
     ]
    }
   ],
   "source": [
    "print(f\"Original dataset size: {len(train_data)}\")\n",
    "print(f\"Balanced dataset size: {len(balanced_data)}\")\n",
    "print(f\"Number of label 1 samples: {len(label_1_data)}\")\n",
    "print(f\"Number of label 0 samples: {len(balanced_label_0_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f85fc96f-db5e-404a-adaa-63bcab4b525a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f81e94b9f1a4637a4329468cba8c11c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1920 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['label', 'loan_data'],\n",
      "    num_rows: 1920\n",
      "})\n",
      "{'label': 0, 'loan_data': 'Loan amount: 25000, DTI: 32.96, Employment Title: Teacher, Employment Length: 10+ years, Home Ownership: RENT, Annual Income: 75000.0, Verification Status: Source Verified, Grade: B-B5, Purpose: debt_consolidation, Description: nan, Title: Debt consolidation, Open Accounts: 12'}\n"
     ]
    }
   ],
   "source": [
    "def rename_columns(example):\n",
    "    example[\"loan_data\"] = example.pop(\"text\")\n",
    "    example[\"label\"] = example.pop(\"label\")\n",
    "    return example\n",
    "\n",
    "dataset = dataset.map(rename_columns)\n",
    "print(dataset)\n",
    "print(dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90edcd60-c5fd-4051-8354-54751d7dcdbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_length = 2048\n",
    "dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
    "load_in_4bit = False # True to use 4bit quantization / reduce memory usage (for T4 GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa4cf3f3-6169-4ddf-af49-4bb19ec2f23c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2024.8: Fast Mistral patching. Transformers = 4.44.0.\n",
      "   \\\\   /|    GPU: NVIDIA A800-SXM4-80GB. Max memory: 79.325 GB. Platform = Linux.\n",
      "O^O/ \\_/ \\    Pytorch: 2.3.1+cu121. CUDA = 8.0. CUDA Toolkit = 12.1.\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.27. FA2 = True]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "292c8cef75b0494facf700b3b6097ed5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model/Mistral-7B-Instruct-v0.3 does not have a padding token! Will use pad_token = [control_768].\n"
     ]
    }
   ],
   "source": [
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    # model_name = \"unsloth/mistral-7b-v0.2-bnb-4bit\",\n",
    "    model_name = \"model/Mistral-7B-Instruct-v0.3\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    dtype = dtype,\n",
    "    load_in_4bit = load_in_4bit,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "12a27128-ba6c-440e-86e5-bd2c65ae993a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Dropout = 0 is supported for fast patching. You are using dropout = 0.05.\n",
      "Unsloth will patch all other layers, except LoRA matrices, causing a performance hit.\n",
      "Unsloth 2024.8 patched 32 layers with 0 QKV layers, 0 O layers and 0 MLP layers.\n"
     ]
    }
   ],
   "source": [
    "# Add LoRA adapters\n",
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = 16, # can improve fine-tuning, at attention/feed fwd layers\n",
    "    target_modules = [\n",
    "        \"q_proj\",\n",
    "        \"k_proj\",\n",
    "        \"v_proj\",\n",
    "        \"o_proj\",\n",
    "        \"gate_proj\",\n",
    "        \"up_proj\",\n",
    "        \"down_proj\",\n",
    "    ],\n",
    "    lora_alpha = 16, # more change to pre-train weights but care overfitting\n",
    "    lora_dropout = 0.05, # any, but 0 if perf opti.\n",
    "    bias = \"none\",    # any, but \"none\" is perf  opti.\n",
    "    use_gradient_checkpointing = True,\n",
    "    random_state = 11,\n",
    "    use_rslora = False,  # support rank stabilized LoRA\n",
    "    loftq_config = None, # LoftQ support\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c1674b9-a396-4ac8-ba9e-30f7692d7250",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt Preparation\n",
    "prompt = \"\"\"You are a highly intelligent and detailed artificial intelligence assistant with a deep understanding of financial data, specifically in predicting loan defaults.\n",
    "Your task is to accurately classify loan data into one of two possible outcomes:\n",
    "- 0: The loan is fully paid off (no default).\n",
    "- 1: The loan has defaulted (borrower failed to meet the repayment terms).\n",
    "\n",
    "The input data will provide various details about the loan and the borrower's financial situation. Your goal is to carefully analyze this information and determine the loan's status based on the provided features.\n",
    "\n",
    "You are expected to generate a response that is one of the following labels:\n",
    "- 0: The loan is fully paid off.\n",
    "- 1: The loan has defaulted.\n",
    "\n",
    "Your classification must be precise and match the best possible outcome for the given loan data.\n",
    "\n",
    "Here is the loan data you need to classify:\n",
    "### Loan Data:\n",
    "{loan_data}\n",
    "### Loan Status:\n",
    "{loan_status}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "50295f2f-1d5c-4653-819a-3493201ecd68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add EOS special token, according to previously loaded tokenizer\n",
    "EOS_TOKEN = tokenizer.eos_token\n",
    "def format_prompts(examples):\n",
    "    inputs = examples[\"loan_data\"]\n",
    "    outputs = examples[\"label\"]\n",
    "    texts = []\n",
    "    for inp, output in zip(inputs, outputs):\n",
    "        # Add end of string token to prevent infinite generations.\n",
    "        text = prompt.format(loan_data=inp, loan_status=output) + EOS_TOKEN\n",
    "        texts.append(text)\n",
    "    return {\"text\":texts}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f9affaca-9604-4dc0-b24a-306d05d6e2b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98aa08e35347482a823a57e07eb310fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1920 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset: Dataset({\n",
      "    features: ['label', 'loan_data', 'text'],\n",
      "    num_rows: 1920\n",
      "})\n",
      "You are a highly intelligent and detailed artificial intelligence assistant with a deep understanding of financial data, specifically in predicting loan defaults.\n",
      "Your task is to accurately classify loan data into one of two possible outcomes:\n",
      "- 0: The loan is fully paid off (no default).\n",
      "- 1: The loan has defaulted (borrower failed to meet the repayment terms).\n",
      "\n",
      "The input data will provide various details about the loan and the borrower's financial situation. Your goal is to carefully analyze this information and determine the loan's status based on the provided features.\n",
      "\n",
      "You are expected to generate a response that is one of the following labels:\n",
      "- 0: The loan is fully paid off.\n",
      "- 1: The loan has defaulted.\n",
      "\n",
      "Your classification must be precise and match the best possible outcome for the given loan data.\n",
      "\n",
      "Here is the loan data you need to classify:\n",
      "### Loan Data:\n",
      "Loan amount: 25000, DTI: 32.96, Employment Title: Teacher, Employment Length: 10+ years, Home Ownership: RENT, Annual Income: 75000.0, Verification Status: Source Verified, Grade: B-B5, Purpose: debt_consolidation, Description: nan, Title: Debt consolidation, Open Accounts: 12\n",
      "### Loan Status:\n",
      "0</s>\n"
     ]
    }
   ],
   "source": [
    "# Building prompts\n",
    "dataset= dataset.map(format_prompts, batched = True)\n",
    "\n",
    "# Print a sample :\n",
    "print(\"dataset:\", dataset)\n",
    "print(dataset[0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e21a9860-4810-47df-bc38-f28cb51bfe92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# è‡ªå®šä¹‰Trainerä»¥ä½¿ç”¨è‡ªå®šä¹‰æŸå¤±å‡½æ•°\n",
    "class CustomTrainer(Trainer):\n",
    "    def __init__(self, *args, dataset_text_field=None, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.dataset_text_field = dataset_text_field  # æ·»åŠ  dataset_text_field å­—æ®µ\n",
    "        self.train_dataset = self.train_dataset.map(self.tokenize_function, batched=True)\n",
    "\n",
    "        self.train_dataset = self.train_dataset.remove_columns([\"loan_data\", \"text\"])\n",
    "        \n",
    "    def tokenize_function(self, examples):\n",
    "        # ä½¿ç”¨ tokenizer å¯¹ text è¿›è¡Œç¼–ç ï¼Œç”Ÿæˆ input_ids å’Œ attention_mask\n",
    "        return self.tokenizer(examples[self.dataset_text_field], padding=\"max_length\", truncation=True)\n",
    "        \n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        # å¦‚æœæœ‰è‡ªå®šä¹‰çš„ dataset_text_field ä½¿ç”¨å®ƒ\n",
    "        # print(\"inputs:\", inputs)\n",
    "        inputs = {key: val.to(model.device) for key, val in inputs.items()}  # å°† inputs ç§»åŠ¨åˆ°æ¨¡å‹æ‰€åœ¨çš„è®¾å¤‡\n",
    "\n",
    "        # è·å–æ¨¡å‹çš„è¾“å‡º\n",
    "        outputs = model(input_ids=inputs[\"input_ids\"], attention_mask=inputs[\"attention_mask\"])\n",
    "        logits = outputs.logits\n",
    "        labels = inputs[\"labels\"]\n",
    "\n",
    "        # è·å–ç‰¹å¾ï¼ˆå‡è®¾ç‰¹å¾åœ¨ inputs[\"features\"]ï¼‰\n",
    "        features = inputs[\"features\"] if \"features\" in inputs else torch.ones((logits.shape[0], len(feature_importance))).to(logits.device)\n",
    "\n",
    "        # è°ƒç”¨è‡ªå®šä¹‰æŸå¤±å‡½æ•°\n",
    "        loss = WeightedCrossEntropyLoss(importance_tensor)(logits, labels, features)\n",
    "\n",
    "        return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "700d03ad-4910-469d-8212-23de906e3e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "training_args = TrainingArguments(\n",
    "    per_device_train_batch_size = 2,\n",
    "    gradient_accumulation_steps = 4,\n",
    "    warmup_steps = 5,\n",
    "    num_train_epochs = 1,\n",
    "    # max_steps = 110,\n",
    "    learning_rate = 2e-4, # 2e-5\n",
    "    fp16 = not torch.cuda.is_bf16_supported(),\n",
    "    bf16 = torch.cuda.is_bf16_supported(),\n",
    "    optim = \"adamw_8bit\",\n",
    "    weight_decay = 0.01,\n",
    "    lr_scheduler_type = \"linear\",\n",
    "    seed = 11,\n",
    "    output_dir = \"outputs/mistral-7b-instruct-v0.3-0910\",\n",
    "    run_name = \"mistral-7b-instruct-v0.3\",\n",
    "    logging_strategy = 'steps',\n",
    "    logging_steps = 1,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=10,\n",
    "    save_total_limit = 2,\n",
    "    report_to = \"wandb\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "24b5a79d-f8bb-4998-aa5e-08a190bd7ef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "Parameter 'function'=<bound method CustomTrainer.tokenize_function of <__main__.CustomTrainer object at 0x7f4a0c1371c0>> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "460f63d66edb4aadbec6cc7ed75ab2ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1920 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainer.dataset: Dataset({\n",
      "    features: ['label', 'input_ids', 'attention_mask'],\n",
      "    num_rows: 1920\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# init the trainer\n",
    "trainer = CustomTrainer(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    train_dataset = dataset,\n",
    "    dataset_text_field = \"text\",\n",
    "    args = training_args\n",
    ")\n",
    "print(\"trainer.dataset:\", trainer.train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9dc73b8e-92ff-4e6e-b05c-56e99ad2b99d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
      "   \\\\   /|    Num examples = 1,920 | Num Epochs = 1\n",
      "O^O/ \\_/ \\    Batch size per device = 2 | Gradient Accumulation steps = 4\n",
      "\\        /    Total batch size = 8 | Total steps = 240\n",
      " \"-____-\"     Number of trainable parameters = 41,943,040\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjunjie_chiang\u001b[0m (\u001b[33mjjchiang\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.9 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/hpc2hdd/home/simonsyguo/junjiejiang/algorithm/FinLLM_loan_pred/wandb/run-20240910_205925-oajd2sdy</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jjchiang/huggingface/runs/oajd2sdy' target=\"_blank\">mistral-7b-instruct-v0.3</a></strong> to <a href='https://wandb.ai/jjchiang/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/jjchiang/huggingface' target=\"_blank\">https://wandb.ai/jjchiang/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/jjchiang/huggingface/runs/oajd2sdy' target=\"_blank\">https://wandb.ai/jjchiang/huggingface/runs/oajd2sdy</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='240' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  6/240 07:56 < 7:44:39, 0.01 it/s, Epoch 0.02/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>14.290600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>14.473900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>10.074600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>7.718900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m'''train'''\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/finetune_jjj/lib/python3.10/site-packages/transformers/trainer.py:1948\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1946\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1947\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1948\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1949\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1950\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1951\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1952\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1953\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<string>:368\u001b[0m, in \u001b[0;36m_fast_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "'''train'''\n",
    "trainer = trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
